---
title: "Untitled"
output: html_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse);library(tidygraph);library(tidytext);library(ggraph);library(visNetwork);library(paletteer)

knitr::opts_chunk$set(
  fig.width=6,fig.asp = 0.618,dpi=300,echo=FALSE,message=FALSE,warning=FALSE
)

motifs <- feather::read_feather("../data/motifs.feather")
source("../prep/motif_network.R")
```


- Read in ATU Tale Type sequences
- Create tidy dataset (1 col per tale, 1 for entire seq of motifs, add seq number)
- Join TMI data to tidy ATU by `motif id` field

# Summarize frequency of occurrences of motif

- Which motifs are used most often in ATU?
- Which motif sections are used most often in ATU?
- Which motifs are not mentioned at all in ATU?
- Which motifs are used least in ATU, excluding high level groupings?
- Which motifs are from common tale sections, but not used?

# Cleaning the ATU Tale Summaries

This will require extracting each tale summary from the text document, tokenized with one phrase per row, as well as the following flags: `tale_id`,`seq_in_tale`,`flagged_motif`.

- Find potential delimiters within the text to allow for tokenization



# Detecting additional motifs in tale summaries

Automatically locate new, yet-to-be-discovered motifs within the ATU tale summaries.  This seems the best source, because many of the motifs have already been identified by experts and the index thus contains a kind of built-in accuracy rating for any newly applied motifs flagging algorithms.  I.e. we can look at the proportion of the already flagged motifs which any new algorithm achieves as a confusion matrix.

If the algorithm which best matches the existing flags also matches other motifs from the index, then we can consider using these additional motifs within the motif sequences which form the tale summaries.

In order to accomplish this matching, we will need a more in-depth look at options for 

- run through a window of n-grams within the tale summary and look for fuzzy matching using string distribution methods (e.g. longest common substring).  Seems computationally expensive.
- break down sentences/clauses of tale summaries and generate best-guess topic models among available motifs from TMI.
- take sequence of words into account by using `lda2vec` approach

Will want to test output using "Tales of Magic", to allow for expert review.

The method for eliminating false positives may need to include a manual review by a group of university-affiliated experts if we want to arrive at a "gold-standard" set of narrative sequences.

Other than topic modeling, we might also take the approach where the sentence/fragment immediately preceding the motif tag from Uther is taken as the data and the motif flag is viewed as the correct classification.  Form this, we might train a model to classify the text correctly when presented with new fragments.

# Apply to new texts

Once this is done, apply the method/model to a new set of tale summaries, such as Shakespeare's plays or Greek myths. 

What we don't know is whether the terms are repeated using the same precise diction as in the original sources.  For this reason, it seems that using a larger library of semantic associations such as WordNet would be a sensible choice, since the similar word in one summary (e.g. "god") would then be linked to a corresponding term in another summary (e.g. "deity").  

At this point, we hit an interesting problem, both with:

- identification of motifs in tales
- identifying novel groupings through unsupervised methods (e.g. topic models, hierarchical clustering)

For instance, if there are two motif names, one which states "god created", and the other which says "deity made", a bag-of-words approach such as topic modeling will not pick up the association.  Thus, pulling in a range of synonyms and either (a) normalizing to include only a single synonym, or (b) including a range of synonyms and including these in the model.

Since each word in a motif name will have different synonyms will have different synonyms and parent concepts under which it falls.  We might also look at combinations of parent concepts which contribute to grouping logic.

---

# Wishlist

## Clean tale source variables

- Make discrete logical column for each country
- Make discrete logical column for each tale source

Method: 

- Create union of all possible combinations from list of countries and sources from back matter
- Try using something like `str_detect(notes, country_name)` to find strings and then `pivot_to_wider()` for cols.

